{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ac33478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "from statsmodels.compat.pandas import deprecate_kwarg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# the main library has a small set of functionality\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60bbe95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def get_forcast_per_component(series, st_in, st_out, train_test_size):\n",
    "    \n",
    "    # split into samples\n",
    "    X, y = split_sequence(series, st_in, st_out)\n",
    "\n",
    "    n_features = 1\n",
    "    X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "    \n",
    "    train_X, test_X = X[:train_test_size], X[train_test_size:]\n",
    "    train_y, test_y = y[:train_test_size], y[train_test_size:]\n",
    "\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(st_in, n_features)))\n",
    "    model.add(MaxPooling1D(pool_size=2)) \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu')) \n",
    "    model.add(Dense(st_out)) \n",
    "    model.compile(optimizer='adam', loss='mse', metrics=[metrics.mae, 'accuracy'])\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(train_X, train_y, epochs=150, verbose=0)\n",
    "    \n",
    "    # predict \n",
    "    predicted = []\n",
    "    for i in range(len(test_X)):\n",
    "        x_input = test_X[i].reshape(1, st_in, n_features)\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        \n",
    "        #predicted.append(np.rint(yhat[0]))   \n",
    "        predicted.append(np.around(yhat[0], decimals=1)) \n",
    "    predicted = np.array(predicted)\n",
    "    return predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cf986f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data \n",
    "trs = pd.read_csv(\"data/transactions.csv\")\n",
    "trs['date'] = pd.to_datetime(trs['date'])\n",
    "trs['date'] = pd.to_datetime(trs['date'])\n",
    "t2day = trs['date'].value_counts().sort_values()\n",
    "t2day = t2day.to_frame()\n",
    "series = t2day.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35e84c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-366598da8e70>:2: FutureWarning: the 'freq'' keyword is deprecated, use 'period' instead\n",
      "  dati_scomp = seasonal_decompose(series, model = 'multiplicative', freq = 7)\n"
     ]
    }
   ],
   "source": [
    "# decomponi i dati in trend, residual e seasonal\n",
    "dati_scomp = seasonal_decompose(series, model = 'multiplicative', freq = 7)\n",
    "\n",
    "\n",
    "\n",
    "trend = dati_scomp.trend.values\n",
    "seasonal = dati_scomp.seasonal.values\n",
    "residual = dati_scomp.resid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec4b8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = trend[np.logical_not(np.isnan(trend))]\n",
    "seasonal = seasonal[np.logical_not(np.isnan(seasonal))]\n",
    "residual = residual[np.logical_not(np.isnan(residual))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182652e",
   "metadata": {},
   "outputs": [],
   "source": [
    " # imposta step di previsione e chiama funzione get_forcast_per_component su ogni componente\n",
    "n_steps_in, n_steps_out = 26, 26\n",
    "train_test_size = 9000\n",
    "\n",
    "forcasted_trend = get_forcast_per_component(trend, n_steps_in, n_steps_out, train_test_size)\n",
    "forcasted_residual = get_forcast_per_component(residual, n_steps_in, n_steps_out, train_test_size)\n",
    "forcasted_season = get_forcast_per_component(seasonal, n_steps_in, n_steps_out, train_test_size)\n",
    "\n",
    "# combina le previsioni \n",
    "final_prediction = forcasted_trend + forcasted_residual + forcasted_season\n",
    "\n",
    "# fai lo split del serie dati originale\n",
    "X, y = split_sequence(kk['nr_people'].values, n_steps_in, n_steps_out) \n",
    "\n",
    "# prepare train-test della serie originale\n",
    "train_X, train_y = X[:train_test_size], X[train_test_size:]\n",
    "train_y, test_y = y[:train_test_size], y[train_test_size:]\n",
    "\n",
    "# assegna a expected il valore del test set\n",
    "expected = test_y\n",
    "\n",
    "# calcola differenza (errore) tra predicted e expected \n",
    "difference = abs(expected - final_prediction)\n",
    "\n",
    "# calcola errore medio e altre misure \n",
    "mean_error =  np.reshape(difference, difference.shape[0] * difference.shape[1])\n",
    "print('Mean error', np.mean(mean_error))\n",
    "    \n",
    "# collect data 2 dictionary\n",
    "minimum = np.amin(mean_error)   \n",
    "per75 = np.percentile(mean_error, 75)\n",
    "per50 = np.percentile(mean_error, 50)\n",
    "per25 = np.percentile(mean_error, 25)\n",
    "maximum = np.amax(mean_error)\n",
    "l5i = [minimum, per25, per50, per75, maximum]\n",
    "dict2data[cell] = l5i\n",
    "    \n",
    "MAPE = np.mean(abs(100 * (difference/expected)))\n",
    "dict2MAPE[cell] = MAPE\n",
    "    \n",
    "with open('MAE_error_data_4_CNN_with_STL_Decomposition_in_26_out_26_period_96.csv', 'w') as f:\n",
    "    for key, value in dict2data.items():\n",
    "        f.write('%s:%s\\n' % (key, value))\n",
    "        \n",
    "with open('MAPE_error_data_4_CNN_with_STL_Decomposition_in_26_out_26_period_96.csv', 'w') as f:\n",
    "    for key, value in dict2MAPE.items():\n",
    "        f.write('%s:%s\\n' % (key, value))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09785a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6629c74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce39291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
